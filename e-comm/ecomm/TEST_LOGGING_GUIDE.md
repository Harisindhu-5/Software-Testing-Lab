# Test Logging System Guide

## Overview

The e-commerce application now includes a comprehensive test logging system that writes detailed logs to files while showing only essential information in the terminal. This system supports multiple test types including Django tests, Selenium WebDriver tests, and Pytest tests.

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd ecomm
pip install -r requirements-testing.txt
```

### 2. Set Up Database

```bash
python manage.py migrate
```

### 3. Run Tests with Logging

```bash
# Run all tests with logging
python run_tests.py --all

# Run specific test types
python run_tests.py --unit
python run_tests.py --selenium
python run_tests.py --pytest
```

## ğŸ“ Log File Structure

When you run tests, the system creates a `test_logs` directory with the following structure:

```
test_logs/
â”œâ”€â”€ django_detailed_20241201_143022.log
â”œâ”€â”€ django_summary_20241201_143022.log
â”œâ”€â”€ django_errors_20241201_143022.log
â”œâ”€â”€ django_performance_20241201_143022.log
â”œâ”€â”€ django_stats_20241201_143022.json
â”œâ”€â”€ selenium_detailed_20241201_143022.log
â”œâ”€â”€ selenium_summary_20241201_143022.log
â”œâ”€â”€ selenium_errors_20241201_143022.log
â”œâ”€â”€ selenium_performance_20241201_143022.log
â”œâ”€â”€ selenium_stats_20241201_143022.json
â”œâ”€â”€ pytest_detailed_20241201_143022.log
â”œâ”€â”€ pytest_summary_20241201_143022.log
â”œâ”€â”€ pytest_errors_20241201_143022.log
â”œâ”€â”€ pytest_performance_20241201_143022.log
â””â”€â”€ pytest_stats_20241201_143022.json
```

## ğŸ“Š Log File Types

### 1. Detailed Logs (`*_detailed_*.log`)
- **Purpose**: Complete test execution details
- **Content**: 
  - Test start/end times
  - Individual test results
  - Performance metrics
  - Database operations
  - Selenium actions
  - Error details
  - Stack traces

### 2. Summary Logs (`*_summary_*.log`)
- **Purpose**: High-level test results
- **Content**:
  - Test pass/fail status
  - Test counts
  - Session summaries
  - Error summaries

### 3. Error Logs (`*_errors_*.log`)
- **Purpose**: Error tracking and debugging
- **Content**:
  - Failed test details
  - Error messages
  - Stack traces
  - Exception information

### 4. Performance Logs (`*_performance_*.log`)
- **Purpose**: Performance monitoring
- **Content**:
  - Test execution times
  - Database query times
  - Page load times
  - Memory usage
  - Response times

### 5. Statistics Files (`*_stats_*.json`)
- **Purpose**: Structured test data
- **Content**:
  - Test statistics
  - Performance metrics
  - Test details
  - Session information

## ğŸ§ª Running Different Test Types

### 1. Django Tests

```bash
# Run all Django tests
python run_tests.py --all

# Run specific test categories
python run_tests.py --unit
python run_tests.py --integration
python run_tests.py --performance
python run_tests.py --security

# Run with coverage
python run_tests.py --coverage
```

**Terminal Output:**
```
ğŸš€ Starting DJANGO tests...
ğŸ“ Logs: test_logs
ğŸ”„ Running: test_user_creation
âœ… PASS: test_user_creation
ğŸ”„ Running: test_product_creation
âœ… PASS: test_product_creation
ğŸ—„ï¸ DB: Database transaction: User creation
ğŸ—„ï¸ DB: Database transaction: Product creation

============================================================
TEST SUMMARY
============================================================
Total Tests: 15
Passed: 14
Failed: 1
Duration: 12.34s
Success Rate: 93.3%
Logs saved to: test_logs
```

### 2. Selenium WebDriver Tests

```bash
# Run Selenium tests
python run_tests.py --selenium

# Or run directly
python shop/selenium_test_runner.py
```

**Terminal Output:**
```
ğŸš€ Starting SELENIUM tests...
ğŸ“ Logs: test_logs
ğŸ”§ SETUP: Initializing Chrome WebDriver
âœ… PASS: WebDriver Setup
ğŸ”„ Running: User Registration Test
âœ… PASS: User Registration Test
ğŸ”„ Running: User Login Test
âœ… PASS: User Login Test
ğŸ”„ Running: Product Browsing Test
âœ… PASS: Product Browsing Test

============================================================
SELENIUM TEST RESULTS
============================================================
User Registration Test    : âœ… PASS
User Login Test          : âœ… PASS
Product Browsing Test    : âœ… PASS
Add to Cart Test         : âœ… PASS
Checkout Process Test    : âœ… PASS
Dynamic Elements Test    : âœ… PASS
Error Handling Test      : âœ… PASS

------------------------------------------------------------
Total Tests: 7
Passed: 7
Failed: 0
Success Rate: 100.0%
```

### 3. Pytest Tests

```bash
# Run Pytest tests
python run_tests.py --pytest

# Or run directly
python shop/pytest_test_runner.py
```

**Terminal Output:**
```
ğŸš€ Starting PYTEST tests...
ğŸ“ Logs: test_logs
ğŸ”„ Running: Pytest Unit Tests
âœ… PASS: Pytest Unit Tests
ğŸ”„ Running: Pytest Integration Tests
âœ… PASS: Pytest Integration Tests
ğŸ”„ Running: Pytest Performance Tests
âœ… PASS: Pytest Performance Tests

============================================================
PYTEST TEST RESULTS
============================================================
Unit Tests           : âœ… PASS
Integration Tests    : âœ… PASS
Performance Tests    : âœ… PASS
Security Tests       : âœ… PASS
Parametrized Tests   : âœ… PASS
Fixture Tests        : âœ… PASS
Coverage Tests       : âœ… PASS

------------------------------------------------------------
Total Test Variants: 7
Passed: 7
Failed: 0
Success Rate: 100.0%
```

## ğŸ“‹ Detailed Log Examples

### Django Detailed Log Example

```
2024-12-01 14:30:22,123 - django_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - django_detailed - INFO - TEST SESSION STARTED
2024-12-01 14:30:22,123 - django_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - django_detailed - INFO - Test Type: django
2024-12-01 14:30:22,123 - django_detailed - INFO - Timestamp: 20241201_143022
2024-12-01 14:30:22,123 - django_detailed - INFO - Session Info: {
  "command": "python manage.py test -v 2",
  "description": "All Tests",
  "test_type": "django",
  "working_directory": "/path/to/ecomm"
}
2024-12-01 14:30:22,124 - django_detailed - INFO - Starting test: test_user_creation
2024-12-01 14:30:22,125 - django_detailed - INFO - Database operation: User creation
2024-12-01 14:30:22,126 - django_detailed - INFO - âœ… Test PASSED: test_user_creation (Duration: 0.01s)
2024-12-01 14:30:22,127 - django_detailed - DEBUG - Test details: {
  "name": "test_user_creation",
  "status": "PASS",
  "duration": 0.01,
  "details": {
    "exit_code": 0,
    "stdout_lines": 45,
    "stderr_lines": 0
  }
}
```

### Selenium Detailed Log Example

```
2024-12-01 14:30:22,123 - selenium_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - selenium_detailed - INFO - TEST SESSION STARTED
2024-12-01 14:30:22,123 - selenium_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - selenium_detailed - INFO - Test Type: selenium
2024-12-01 14:30:22,123 - selenium_detailed - INFO - ğŸ”§ SETUP: Initializing Chrome WebDriver
2024-12-01 14:30:22,124 - selenium_detailed - INFO - âœ… Test PASSED: WebDriver Setup
2024-12-01 14:30:22,125 - selenium_detailed - INFO - Starting test: User Registration Test
2024-12-01 14:30:22,126 - selenium_detailed - INFO - Selenium action: Navigate to signup page
2024-12-01 14:30:22,127 - selenium_detailed - INFO - Selenium action: Fill username field on element: username with value: seleniumuser
2024-12-01 14:30:22,128 - selenium_detailed - INFO - Selenium action: Fill email field on element: email with value: selenium@test.com
2024-12-01 14:30:22,129 - selenium_detailed - INFO - Selenium action: Submit registration form
2024-12-01 14:30:22,130 - selenium_detailed - INFO - âœ… Test PASSED: User Registration Test (Duration: 0.05s)
```

### Pytest Detailed Log Example

```
2024-12-01 14:30:22,123 - pytest_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - pytest_detailed - INFO - TEST SESSION STARTED
2024-12-01 14:30:22,123 - pytest_detailed - INFO - ============================================================
2024-12-01 14:30:22,123 - pytest_detailed - INFO - Test Type: pytest
2024-12-01 14:30:22,123 - pytest_detailed - INFO - Starting test: Pytest Unit Tests
2024-12-01 14:30:22,124 - pytest_detailed - INFO - Pytest Command: pytest shop/tests.py -v -k "UserModelTest or ProductModelTest"
2024-12-01 14:30:22,125 - pytest_detailed - INFO - âœ… PASS: test_user_creation
2024-12-01 14:30:22,126 - pytest_detailed - INFO - âœ… PASS: test_product_creation
2024-12-01 14:30:22,127 - pytest_detailed - INFO - Pytest Summary: 2 passed, 0 failed in 0.03s
```

## ğŸ“ˆ Performance Monitoring

### Performance Log Example

```
2024-12-01 14:30:22,123 - django_performance - INFO - Command Duration: 12.34 seconds
2024-12-01 14:30:22,124 - django_performance - INFO - Page Load Time: 0.85 seconds
2024-12-01 14:30:22,125 - django_performance - INFO - Database Query Time: 0.12 seconds
2024-12-01 14:30:22,126 - django_performance - INFO - Memory Usage: 45.2 MB
2024-12-01 14:30:22,127 - django_performance - INFO - Response Time: 0.23 seconds
```

## ğŸ” Error Tracking

### Error Log Example

```
2024-12-01 14:30:22,123 - django_errors - ERROR - FAIL: test_user_creation_with_invalid_email
2024-12-01 14:30:22,123 - django_errors - ERROR - Error: ValidationError: Enter a valid email address.
2024-12-01 14:30:22,124 - django_errors - ERROR - Traceback (most recent call last):
  File "shop/tests.py", line 45, in test_user_creation_with_invalid_email
    user = User.objects.create_user(username="test", email="invalid-email")
  File "django/db/models/manager.py", line 85, in create_user
    return self._create_user(username, email, password, **extra_fields)
```

## ğŸ“Š Statistics Files

### JSON Statistics Example

```json
{
  "total_tests": 15,
  "passed_tests": 14,
  "failed_tests": 1,
  "skipped_tests": 0,
  "start_time": 1701435022.123,
  "end_time": 1701435034.456,
  "duration": 12.333,
  "test_details": [
    {
      "name": "test_user_creation",
      "status": "PASS",
      "duration": 0.01,
      "details": {
        "exit_code": 0,
        "stdout_lines": 45,
        "stderr_lines": 0
      }
    },
    {
      "name": "test_user_creation_with_invalid_email",
      "status": "FAIL",
      "duration": 0.02,
      "error": "ValidationError: Enter a valid email address.",
      "details": {
        "exception_type": "ValidationError",
        "test_type": "django"
      }
    }
  ]
}
```

## ğŸ› ï¸ Advanced Usage

### 1. Custom Test Categories

```bash
# Run tests by categories
python run_tests.py --categories

# Available categories:
# - unit
# - integration
# - functional
# - performance
# - security
# - edge
# - api
# - validation
# - concurrency
# - error
# - usability
```

### 2. Custom Test Selection

```bash
# Run custom test
python run_tests.py --custom

# Available test classes:
# 1. UserModelTest
# 2. ProductModelTest
# 3. CartModelTest
# 4. OrderModelTest
# 5. CartIntegrationTest
# 6. OrderIntegrationTest
# 7. UserWorkflowTest
# 8. PerformanceTest
# 9. SecurityTest
# 10. EdgeCaseTest
# 11. APITest
# 12. DataValidationTest
# 13. ConcurrencyTest
# 14. ErrorHandlingTest
# 15. UsabilityTest
# 16. ComprehensiveTestSuite
```

### 3. Load and Stress Testing

```bash
# Run load testing
python run_tests.py --load

# Run stress testing
python run_tests.py --stress
```

### 4. Test Statistics

```bash
# Show test statistics
python run_tests.py --stats
```

## ğŸ”§ Configuration

### Log Directory

The logs are saved in the `test_logs` directory by default. You can change this by modifying the `log_dir` parameter in the logger initialization.

### Log Levels

- **DEBUG**: Detailed information for debugging
- **INFO**: General information about test execution
- **WARNING**: Warning messages
- **ERROR**: Error messages and failures

### Timestamp Format

Log files use the timestamp format: `YYYYMMDD_HHMMSS`

## ğŸ“ Best Practices

### 1. Regular Log Review

- Check summary logs for quick overview
- Review error logs for failed tests
- Monitor performance logs for bottlenecks
- Use detailed logs for debugging

### 2. Log File Management

```bash
# Clean old log files (older than 30 days)
find test_logs -name "*.log" -mtime +30 -delete

# Archive logs monthly
tar -czf test_logs_$(date +%Y%m).tar.gz test_logs/
```

### 3. Integration with CI/CD

```yaml
# Example GitHub Actions workflow
- name: Run Tests with Logging
  run: |
    python run_tests.py --all
    # Upload logs as artifacts
    tar -czf test_logs.tar.gz test_logs/
    # Upload artifacts
    actions/upload-artifact@v2
      name: test-logs
      path: test_logs.tar.gz
```

## ğŸ› Troubleshooting

### Common Issues

1. **Log Directory Not Created**
   ```bash
   # Ensure directory exists
   mkdir -p test_logs
   ```

2. **Permission Issues**
   ```bash
   # Fix permissions
   chmod 755 test_logs/
   ```

3. **Selenium WebDriver Issues**
   ```bash
   # Install Chrome WebDriver
   pip install webdriver-manager
   ```

4. **Pytest Not Found**
   ```bash
   # Install pytest
   pip install pytest pytest-django
   ```

### Debug Mode

```bash
# Run with verbose output
python run_tests.py --all --verbose

# Check log files in real-time
tail -f test_logs/django_detailed_*.log
```

## ğŸ“š Additional Resources

- [Django Testing Documentation](https://docs.djangoproject.com/en/stable/topics/testing/)
- [Selenium WebDriver Documentation](https://selenium-python.readthedocs.io/)
- [Pytest Documentation](https://docs.pytest.org/)
- [Python Logging Documentation](https://docs.python.org/3/library/logging.html)

## ğŸ¯ Summary

The test logging system provides:

âœ… **Comprehensive logging** for all test types  
âœ… **Minimal terminal output** with essential information  
âœ… **Detailed file logs** for debugging and analysis  
âœ… **Performance monitoring** with metrics  
âœ… **Error tracking** with stack traces  
âœ… **Statistics generation** in JSON format  
âœ… **Multiple test frameworks** support (Django, Selenium, Pytest)  
âœ… **Easy integration** with CI/CD pipelines  

This system makes the e-commerce application an excellent tool for learning and practicing software testing methodologies while maintaining detailed records of all test executions. 